\chapter{Conclusions and future works}

\section{Summary}
The potential of the newest models of machine learning in the CPS field is underexploited: while in controlled scenarios many classical control methods are still effective, in open world scenarios they are not always a viable option.
Better alternatives like reinforcement learning, though promising, struggle to give an adequate safety guarantee for real-world applications.

We wanted to address such problem drawing inspiration from GANs literature: two opposing NNs that learn from each other.
The outcome of the learning procedure is one \textbf{defender} NN that is able to face in a safe and robust way the scenarios generated by the \textbf{attacker} NN.

We tested our method in two different settings: the traditional \textbf{cruise control} problem and  the \textbf{platooning} one.


\section{Conclusions}
In both the case studies, our architecture behaved well and showed promising results, a potential for further research on the topic.

With the presented architecture we showed a possible way of achieving both safety and interpretability of the model.
The \textit{defender}, in fact, can safely overcome most of the presented situations, some of which are indeed unrealistic corner-cases.
The \textit{attacker}, on the other side, is able to give insight on which are the most insidious configurations of the environment, allowing to deploy better systems to face them.

The architecture proved itself to be robust even in case of sparse exploration of the space of the initial configuration.
Starting for an unknown state, in fact, is almost always able to reach a known and safe state.

The results presented are encouraging.

\section{Future work}
The presented architecture is quite complex and requires a deeper exploration in order to uncover the full potential.

The architecture would greatly benefits of some optimizations to enable the processing of simulations \textit{mini-batches} in parallel.

It would be interesting to try the architecture on different CPS and different problems.
A possible future development, in fact, could be to apply this architecture to control non-differentiable models.
It could be achieved by training a differentiable NN as a surrogate of the non-differentiable system and use it as model $\mathcal{M}$.

Another matter that requires more attention is the choice of the points on the \textit{hyper-grid} for the training.
While at the moment we sample it uniformly, other smarter strategies could be applied since not every configuration is equally probable.